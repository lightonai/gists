{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading\n",
    "We start by loading the CNN used to extract the convolutional features.  \n",
    "We use the `densenet169` pretrained on ImageNet available in the `torchvision` library. Moreover, since we do not need the linear section at the end we select only the convolutional part with `.features`.  \n",
    "\n",
    "We also set the device for any future computations: you can either pick `cpu` if you want to carry out all computations on a CPU, or `cuda:x` if you are operating a machine with one or more GPUs. In the last case the GPU used will be the number `x`, usually starting from 0. \n",
    "\n",
    "Finally, we need to know the size of the convolutional features in output to the network, so we pass a dummy input to retrieve this information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output size =  81536\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import densenet169\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "model = densenet169(pretrained=True).features\n",
    "model.to(device)\n",
    "\n",
    "input_shape=(1, 3, 224, 224)\n",
    "\n",
    "dummy_input = torch.ones(input_shape, requires_grad=False).to(device)\n",
    "output_size = model(dummy_input).shape[1:].numel()\n",
    "\n",
    "print(\"model output size = \", output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloading\n",
    "\n",
    "Next we load the dataset images. We use the `STL10` dataset available in the `torchvision` library in this notebook.  \n",
    "We start by setting the following parameters:\n",
    "- `root`: path to data directory. If no dataset is present, it will be downloaded here;\n",
    "-  transforms to apply to each sample. We stick with a simple normalization and resize the images to (224, 224)\n",
    "- `batch_size`: batch size for the number of samples to be processed at the same time;\n",
    "- `num_workers`: Number of CPU cores to use by the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "root = \"/data/mldata/STL10/\"\n",
    "normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "transform = transforms.Compose([transforms.Resize(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                normalize\n",
    "                                ])\n",
    "batch_size = 32\n",
    "num_workers = 12\n",
    "\n",
    "    \n",
    "train_data = datasets.STL10(root=root, split='train', transform=transform, download=True)\n",
    "test_data = datasets.STL10(root=root, split='test', transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers,drop_last=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=num_workers,drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the convolutional features\n",
    "\n",
    "We need to extract the convolutional features of the train and test set and encode them. We do so with the `get_conv_features` defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "def get_conv_features(loader, model, out_shape, device='cpu'):\n",
    "    \"\"\"\n",
    "    Computes the convolutional features of the images in the loader and encodes them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    loader: torch Dataloader,\n",
    "        contains the images to extract the training features from.\n",
    "    model: torchvision.models,\n",
    "        architecture to use to get the convolutional features.\n",
    "    out_shape: int,\n",
    "        output size of the last layer.\n",
    "    device: string,\n",
    "        device to use for the computation. Choose between 'cpu' and 'gpu:x', where\n",
    "        x is the GPU number. Defaults to 'cpu'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    conv_features: numpy array,\n",
    "        array containing the convolutional features. format is (# of samples * # of features).\n",
    "        They are already moved to CPU.\n",
    "    labels: list of int,\n",
    "        labels associated to each image.\n",
    "    conv_time: float,\n",
    "        time required to compute the convolutional features. It includes the data loading.\n",
    "    encode_time: float,\n",
    "        encoding time, done on the GPU.\n",
    "    \"\"\"\n",
    "\n",
    "    n_images = len(loader.dataset)\n",
    "\n",
    "    batch_size = loader.batch_size\n",
    "\n",
    "    conv_features = torch.FloatTensor(n_images, out_shape).to(device)\n",
    "    labels = np.empty(n_images, dtype='uint8')\n",
    "    model.eval()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, (images, targets) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            conv_features[i * batch_size: (i + 1) * batch_size, :] = outputs.data.view(images.size(0), -1)\n",
    "            labels[i * batch_size: (i + 1) * batch_size] = targets.numpy()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        conv_time = time() - t0\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        start = time()\n",
    "        conv_features = (conv_features > 0)\n",
    "        torch.cuda.synchronize()\n",
    "        encode_time = time() - start\n",
    "\n",
    "        conv_features = conv_features.cpu()\n",
    "\n",
    "    return conv_features, labels, conv_time, encode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train conv features time = 11.76 s\tencoding = 0.00561 s\n",
      "test conv features time  = 18.48 s\tencoding = 0.00708 s\n"
     ]
    }
   ],
   "source": [
    "train_conv_f, train_labels, train_conv_t, train_encode_t = get_conv_features(train_loader, model, output_size,\n",
    "                                                                             device=device)\n",
    "print(\"train conv features time = {0:3.2f} s\\tencoding = {1:1.5f} s\".format(train_conv_t, train_encode_t))\n",
    "\n",
    "test_conv_f, test_labels, test_conv_t, test_encode_t= get_conv_features(test_loader, model, output_size,\n",
    "                                                                        device=device)\n",
    "print(\"test conv features time  = {0:3.2f} s\\tencoding = {1:1.5f} s\".format(test_conv_t, test_encode_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random projection\n",
    "### with GPU\n",
    "\n",
    "We start by generating the random matrix of size will be `(out_shape , n_components)`, where `n_components` is the number of random projections. We split the matrix in `10` blocks, since we will have to move this matrix in GPU memory along with the matrix of convolutional features, and there might not be enough space for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "def generate_RM(n_components, n_features, n_ram=10, normalize=True):\n",
    "    \"\"\"\n",
    "    Generates the splits for the random matrix, ready to be moved to GPU.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    n_ram: int,\n",
    "        number of splits for the random matrix.\n",
    "    n_components: int,\n",
    "        number of random projections.\n",
    "    n_features: int,\n",
    "        number of convolutional features of the input matrix.\n",
    "    normalize: boolean,\n",
    "        if True, normalizes the matrix by dividing each entry by np.sqrt(n_features). defaults to True\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    R: list of numpy array,\n",
    "        blocks of the random projection matrix.\n",
    "    generation_time: float,\n",
    "        time to generate the matrix.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    matrix_shape = (n_features, n_components // n_ram)\n",
    "    R = []\n",
    "    since = time()\n",
    "\n",
    "    for i in range(n_ram):\n",
    "        print('Generating random matrix # ', i + 1)\n",
    "        # allocate the right amount of memory\n",
    "        R_tmp = np.zeros(shape=matrix_shape, dtype='float32')\n",
    "        # fill that amount of memory and no more\n",
    "        R_tmp[:] = np.random.randn(*matrix_shape)\n",
    "        if normalize is True:\n",
    "            R_tmp /= np.sqrt(n_components)\n",
    "        R.append(R_tmp)\n",
    "\n",
    "    generation_time = time() - since\n",
    "\n",
    "    return R, generation_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we generate the matrix, we can perform the projection. We multiply each block of the random matrix with the convolutional feature matrix and we concatenate the partial outputs to obtain the final result. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dot_split(x, random_matrix):\n",
    "    \"\"\"\n",
    "    Computes the random projection dot product on GPU.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x = cupy array,\n",
    "        contains the data to project.\n",
    "    random_matrix = numpy array,\n",
    "        random projection matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    output: cupy array,\n",
    "        contains the random projected matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    rm = cp.asarray(random_matrix)\n",
    "    output = cp.asnumpy(cp.abs(cp.dot(x, rm))**2)\n",
    "    return output\n",
    "\n",
    "def get_rand_features_GPU(R, X):\n",
    "    \"\"\"\n",
    "    Computes the random projection on GPU.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    R: numpy array,\n",
    "        random projection matrix.\n",
    "    X: numpy array,\n",
    "        matrix to project.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    togpu_time: float,\n",
    "        time to move the features to GPU.\n",
    "    proj_time: float,\n",
    "        projection time.\n",
    "        \n",
    "    \"\"\"\n",
    "    random_features = []\n",
    "\n",
    "    # Export the features to GPU\n",
    "    X = cp.asarray(X)\n",
    "\n",
    "    # Do the RP\n",
    "\n",
    "    t0 = time()\n",
    "    for matrix in R:\n",
    "        random_features.append(compute_dot_split(X, matrix))\n",
    "    \n",
    "    # Turn the features back to numpy arrays.\n",
    "    random_features = cp.asnumpy(random_features)\n",
    "    random_features = np.concatenate(random_features, axis=1)\n",
    "    proj_time = time() - t0\n",
    "\n",
    "    return random_features, proj_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing that is left is to pick the number of random features we want to use by setting the `n_components` variable and generate the matrix `R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random matrix #  1\n",
      "Generating random matrix #  2\n",
      "Generating random matrix #  3\n",
      "Generating random matrix #  4\n",
      "Generating random matrix #  5\n",
      "Generating random matrix #  6\n",
      "Generating random matrix #  7\n",
      "Generating random matrix #  8\n",
      "Generating random matrix #  9\n",
      "Generating random matrix #  10\n",
      "Generation time = 456.23 s\n"
     ]
    }
   ],
   "source": [
    "n_components = 120000\n",
    "\n",
    "R, generation_time = generate_RM(n_components, output_size)\n",
    "print(\"Generation time = {0:3.2f} s\".format(generation_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we compute the random features by calling `get_rand_features_GPU`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train projection time = 22.53 s\n",
      "Test projection time = 30.42 s\n"
     ]
    }
   ],
   "source": [
    "train_random_features, train_proj_t = get_rand_features_GPU(R, train_conv_f)\n",
    "print(\"Train projection time = {0:3.2f} s\".format(train_proj_t))\n",
    "\n",
    "test_random_features, test_proj_t = get_rand_features_GPU(R, test_conv_f)\n",
    "print(\"Test projection time = {0:3.2f} s\".format(test_proj_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With OPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the random projection with the OPU we use the `lightonml` library, which provides a simple python API to perform random projections with LightOn’s OPU.\n",
    "\n",
    "We import the `OPUMap` object from the `lightonml` library and we create an instance of the class while passing the number of random projections (`n_components`) as argument.\n",
    "A simple call to `opu.transform(X)` performs the random projection of the input matrix `X`, containing the convolutional features of the train/test set. We store the output matrix in the random_features variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightonml.projections.sklearn import OPUMap\n",
    "\n",
    "def get_random_features(X, n_components):\n",
    "    \"\"\"\n",
    "    Computes the random projection with LightOn's OPU and converts the features to float32.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    X: torch tensor or numpy array,\n",
    "        matrix of convolutional features\n",
    "    n_components: int,\n",
    "        number of random features\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    random_features: numpy array or torch tensor,\n",
    "        matrix of random features;\n",
    "    proj_time: float,\n",
    "        projection time.\n",
    "    decode_time: float,\n",
    "        decoding time.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    opu = OPUMap(n_components=n_components)\n",
    "    \n",
    "    since = time()\n",
    "    random_features = opu.transform(X)\n",
    "    proj_time = time() - since\n",
    "\n",
    "    since = time()\n",
    "    random_features = random_features.type(torch.FloatTensor)\n",
    "    decode_time = time() - since\n",
    "    \n",
    "    return random_features, proj_time, decode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train projection time = 11.29 s\tTrain decode time = 0.16 s\n",
      "Test projection time = 8.48 s\tTest decode time = 0.23 s\n"
     ]
    }
   ],
   "source": [
    "n_components = 120000\n",
    "\n",
    "train_random_features, train_proj_t, decode_train_t = get_random_features(train_conv_f, n_components)\n",
    "print(\"Train projection time = {0:3.2f} s\\tTrain decode time = {1:3.2f} s\".format(train_proj_t, decode_train_t))\n",
    "\n",
    "test_random_features, test_proj_t, decode_test_t = get_random_features(test_conv_f, n_components)\n",
    "print(\"Test projection time = {0:3.2f} s\\tTest decode time = {1:3.2f} s\".format(test_proj_t, decode_test_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the linear classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply fit a linear classifier on the training features and evaluate its performance on the test set. We selected the RidgeClassifier available in `scikit-learn` because of its fast implementation compared to other classifiers like logistic regression.\n",
    "\n",
    "\n",
    "For the regularization coefficient `alpha`, usually values close to 1e6 tend to yield pretty good results with the LightOn’s OPU. If a GPU is used, this value needs to be lowered to 1e3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc = 100.00\tTest acc = 96.90\tFit time = 11.37 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "\n",
    "clf = RidgeClassifier(alpha=1e3)\n",
    "since = time()\n",
    "clf.fit(train_random_features, train_labels)\n",
    "fit_time = time() - since\n",
    "\n",
    "train_accuracy = clf.score(train_random_features, train_labels) * 100\n",
    "test_accuracy = clf.score(test_random_features, test_labels) * 100\n",
    "\n",
    "print('Train acc = {0:3.2f}\\tTest acc = {1:2.2f}\\tFit time = {2:3.2f} s'\n",
    "      .format(train_accuracy, test_accuracy, fit_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (opu-videos)",
   "language": "python",
   "name": "opu-videos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
